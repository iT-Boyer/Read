# 数据密集型应用系统设计

- 描述性能

客户端来测量响应时间很重要

# 2. 数据模型与查询语言

## 关系数据库与文档数据库现状

对于高度关联的数据, 文档模型不太适合, 关系模型可以胜任, 而图模型则是最为自然的

# 5. 数据复制

## 主从复制

### 复制滞后问题

- 读自己的写

![读自己的写](./读自己的写.png)

解决方案

1. 如果用户访问的内容是只有自身可修改的,那么 自己的修改和查询均读取主节点, 访问仅有其他人可修改的内容, 则读取从节点
2. 客户端记住服务端返回的更新时间戳, 读取时带上时间戳, 查询时这条记录的修改时间要大于客户端传过来的时间戳, 如果小于则查下一个db节点, 直到查到大于的为止
3. 建议读从节点的话, 只能读允许最终一致性的数据

- 单调读

同一类查询最好查询同一副本, 当这个副本失效时, 查询下一个副本

![单调读](./单调读.png)

解决方案:

1. 同一用户读到的从节点要一致, 根据用户id哈希方法, 选定从节点, 如果该副本失效, 则路由到另一个副本

## 多主复制

好处

1. 提升性能, 用户可以就近访问数据
2. 容灾

处理写冲突

- 避免冲突

通过不同的userid/地理位置固定写入到一个数据中心

- 收敛于一致状态

1. 给每个写入分配一个时间戳, 大的时间戳可写入

## 无主节点复制

客户端直接向多个节点写请求

![无主节点复制](image-1.png)

如果有n个节点, 写入需要w个节点确认, 读取需要r个节点确认, w + r > n 那么读取的节点一定包含最新值

即使在 w +r >n的情况也有可能返回旧值

- 写操作同时发生
- 写和读操作同时发生, 写操作进一部分副本上完成
- 部分副本写入成功, 部分写入失败, 且写入成功数小于w, 那么已成功的副本不会回滚
- 如果具有新值的节点失效, 但恢复数据来自某个旧值, 则总的新值副本会低于w, 打破了之前的判断条件
- 即使一切正常, 也可能出现边界情况, 参考后续可线性化与quorum

这个方案运维侧不好监控旧值情况

- 宽松的quorum与数据回传

在一个大规模集群中, 节点数远大于n, 客户端在网络中断期间,还能连接到某些数据库节点, 但这些节点不是参与仲裁的数据库节点.

如果接受写请求, 只是将他们暂时写入一些可访问的节点里, 注意这些节点并不在原本的n的节点集合中, 这种方案称为放松式仲裁.

写入和读取仍需要w和r的成功响应, 不过w可能是不在原先仲裁的节点里

当网络问题解决, 临时节点需要把接收到的写入全部发送给仲裁节点.

## 多数据中心操作

解决并发写问题

- 最后写入者获胜

- Happends-before关系和并发

![alt text](image-3.png)

1. 服务器为每个主键维护一个版本号, 每当主键有写入时递增版本号,并将新版本号和写入值一起保存
2. 客户端读取主键时, 服务器将返回所有(未被覆盖的)当前值以及最新的版本号, 且要求写之前, 客户端必须先发送读请求
3. 客户端写主键, 写请求必须包含之前读到的版本号, 读到的值和新值合并后的集合.写请求的响应可以像读操作一样, 会返回所有当前值.
4. 当前服务器收到带有特定版本号的写入时, 覆盖该版本或更低版本的所有值(因为知道这些值 已经被合并到新传入的值集合中), 但必须保存更高版本号和所有值(因为这些值与当前的写操作属于并发)

# 6. 数据分区

## 分区与二级索引

- 基于文档分区和二级索引

场景一个销售二手汽车的网站, 每个列表都有一个唯一的文档id, 用此ID对数据库进行分区

现在用户需要搜索汽车, 可以按汽车颜色、厂商进行过滤, 所以需要在颜色、厂商上设定二级索引

![alt text](image-4.png)

## 基于词条的二级索引分区

另外一种方法, 对所有的数据进行全局索引, 而不是每个分区维护自己的索引

但是全局索引本身也必须进行分区

![alt text](image-2.png)

例如将颜色字母字母从a-m的二级索引都放在一个分区

但是这个会增加写扩大, 一个分区的原始数据需要更新时, 可能涉及到多个分区的二级索引进行写操作

实践中, 全局二级索引的更新通常是异步的

## 分区再平衡

分区再平衡通常至少满足

1. 平衡之后, 负载、数据存储、读写请求在集群内应该更均匀的分布
2. 再平衡的过程中, 数据库应该正常提供服务
3. 避免不必要的迁移, 以加快动态再平衡, 也尽量减少网络和磁盘I/O的影响

## 动态再平衡策略

1. 最好将哈希值划分为不同的区间范围, 然后将每个区间分配给一个分区
2. 不建议使用取mod, 因为节点数变化, 会导致很多关键字的数据所在分区变化

### 固定数量的分区

步骤

1. 创建远超实际节点数的分区数
2. 为每个节点分配多个分区
3. 根据关键字哈希范围分配到不同区

例如, 一个只有10个节点的集群, 数据库一开始就划分1000个分区, 每个节点承受100个分区

如果新增节点, 该新节点从现有每个节点匀走几个分区, 直到再次达到全局平衡

劣势:
使用该策略时, 要确认数据集的总规模高度

### 动态分区

对于采用的关键字分区的数据库, 如果边界设置有问题, 可能所有数据都在一个分区里

大于数量阈值则分裂, 小于数量阈值则合并. 可以设置初始最小分区

### 按节点比例分区

每个节点具有固定数量的分区, 当节点数不变时, 每个分区的大小和数据集大小保持正比增长关系

当节点数增加时, 分区则会调整变小

1. 当一个新的节点加入集群, 他随机选择固定数量的现有分区进行分裂, 拿走这些分区的一半数据量

## 请求路由

方案一: 允许客户端链接任意节点, 如果某节点拥有所请求的分区, 则直接处理, 否则转发到下一个合适的节点
方案二: 所有客户端请求都发送到一个路由层, 由路由层决策转发到哪个分区
方案三: 客户端感知分区与节点分配关系

# 7 事务

## ACID含义

1. 原子性: 要么都成功要么都失败
2. 一致性: 达到预期状态
3. 隔离性: 两个客户端同时++, 要达到加两次的效果
4. 持久性: 事务提交成功, 即使数据库崩溃也要保证数据不丢失

## 弱隔离级别

### 读-提交

- 读数据库时, 只能看到已提交的数据(防止"脏读"")
- 写数据库时, 只会覆盖已成功提交的数据(防止"脏写")

#### 防止脏写

- 脏写: 如果两个事务同时尝试更新相同对象, 如果先写但未提交的事务被后写的覆盖了, 则是脏读

避免脏读的方式是推迟第二个写请求, 直到前面的事务全部完成

#### 实现读-提交

脏写: 数据库一般采用行锁来防止脏写
脏读: 对于每个待更新的对象, 数据库维护旧值、当前持有锁将要设置的新值两个版本, 事务提交后, 能读到新值

### 快照级别隔离与可重复读
